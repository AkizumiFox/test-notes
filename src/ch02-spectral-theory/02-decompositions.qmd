---
chapter-number: 4
filters:
  - latex-environment
  - chapter-number
format:
  pdf:
    documentclass: memoir
    classoption: [13pt, a4paper]
    number-sections: true
    pdf-engine: lualatex
    geometry: [top=30mm, left=25mm, right=25mm, bottom=30mm]
    include-in-header:
      text: |
        \usepackage[quartoenv]{../../config/latex-template}
        \directlua{require("../../config/strip-numbers")}
---

{{< include ../../config/macros.qmd >}}

# Matrix Decompositions

## Introduction

Matrix decompositions factor a matrix into products of simpler matrices. These factorizations reveal structure and enable efficient computation.

## Spectral Decomposition

::: {#thm-spectral}
## Spectral Theorem
Let $\bA \in \R^{n \times n}$ be symmetric. Then $\bA$ can be decomposed as:
$$
\bA = \bQ \bLambda \bQ^\top
$$
where $\bQ$ is orthogonal (its columns are orthonormal eigenvectors of $\bA$) and $\bLambda = \diag(\lambda_1, \ldots, \lambda_n)$ is diagonal (containing the eigenvalues).
:::

## Singular Value Decomposition

::: {#def-svd}
## Singular Value Decomposition (SVD)
Every matrix $\bA \in \R^{m \times n}$ can be factored as:
$$
\bA = \bU \bSigma \bV^\top
$$
where:

- $\bU \in \R^{m \times m}$ is orthogonal (left singular vectors)
- $\bSigma \in \R^{m \times n}$ is diagonal with non-negative entries (singular values)
- $\bV \in \R^{n \times n}$ is orthogonal (right singular vectors)
:::

::: {#thm-svd-rank}
## SVD and Rank
The rank of $\bA$ equals the number of non-zero singular values.
:::

## Applications

::: {#exm-pca}
## Principal Component Analysis
PCA uses the SVD to find the directions of maximum variance in a dataset. If $\bX$ is a centered data matrix, the principal components are the right singular vectors of $\bX$.
:::

## Exercises

::: {#exr-pseudo-inverse}
## Moore-Penrose Pseudoinverse
Using the SVD $\bA = \bU \bSigma \bV^\top$, show that the pseudoinverse is given by $\bA^+ = \bV \bSigma^+ \bU^\top$.
:::
